{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dependencies\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "#Data path\n",
    "path = '/Volumes/Vincent SSD/KU Leuven/PhD AI-CS/Project Data/MNIST/'\n",
    "\n",
    "\n",
    "#Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Running on: {device}')\n",
    "\n",
    "#Define dataloader class\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, X, y=None, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.X.iloc[index, ].values.astype(np.uint8).reshape((28, 28, 1))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.y is not None:\n",
    "            return image, self.y.iloc[index]\n",
    "        else:\n",
    "            return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(path + 'train.csv')\n",
    "test_df = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image shape :  (50000, 784)\n",
      "train label shape :  (50000,)\n",
      "valid image shape :  (10000, 784)\n",
      "valid label image :  (10000,)\n",
      "test image shape  :  (10000, 784)\n",
      "test label image :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(train_df.iloc[:, 1:], train_df['label'], test_size=1/6, random_state=42)\n",
    "\n",
    "y_test = test_df.pop('label')\n",
    "X_test = test_df\n",
    "\n",
    "print('train image shape : ', X_train.shape)\n",
    "print('train label shape : ', y_train.shape)\n",
    "print('valid image shape : ', X_valid.shape)\n",
    "print('valid label image : ', y_valid.shape)\n",
    "print('test image shape  : ', X_test.shape)\n",
    "print('test label image : ', y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape on PyTroch :  torch.Size([128, 1, 28, 28])\n",
      "labels shape on PyTroch :  torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(X=X_train, y=y_train, transform=transform)\n",
    "valid_dataset = MNIST(X=X_valid, y=y_valid, transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(X=X_test, y=y_test, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print('images shape on PyTroch : ', images.size())\n",
    "print('labels shape on PyTroch : ', labels.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # convert tensor (128, 1, 28, 28) --> (128, 1*28*28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "print(model)\n",
    "\n",
    "#Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 1, train loss : 0.4979, valid loss : 0.2682, valid acc : 92.32%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 2, train loss : 0.2599, valid loss : 0.2020, valid acc : 94.36%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 3, train loss : 0.1991, valid loss : 0.1571, valid acc : 95.38%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 4, train loss : 0.1597, valid loss : 0.1346, valid acc : 96.29%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 5, train loss : 0.1361, valid loss : 0.1198, valid acc : 96.40%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 6, train loss : 0.1193, valid loss : 0.1021, valid acc : 96.99%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 7, train loss : 0.1048, valid loss : 0.0969, valid acc : 97.12%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 8, train loss : 0.0944, valid loss : 0.0925, valid acc : 97.20%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 9, train loss : 0.0881, valid loss : 0.0882, valid acc : 97.41%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 10, train loss : 0.0808, valid loss : 0.0843, valid acc : 97.47%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 11, train loss : 0.0748, valid loss : 0.0851, valid acc : 97.56%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 12, train loss : 0.0702, valid loss : 0.0769, valid acc : 97.73%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 13, train loss : 0.0642, valid loss : 0.0768, valid acc : 97.80%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 14, train loss : 0.0607, valid loss : 0.0765, valid acc : 97.76%\n",
      "0 / 50000\n",
      "12800 / 50000\n",
      "25600 / 50000\n",
      "38400 / 50000\n",
      "epoch : 15, train loss : 0.0577, valid loss : 0.0712, valid acc : 97.98%\n"
     ]
    }
   ],
   "source": [
    "#Define the training + validation loops\n",
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (i * 128) % (128 * 100) == 0:\n",
    "            print(f'{i * 128} / 50000')\n",
    "            \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            valid_losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    \n",
    "    accuracy = 100*correct/total\n",
    "    valid_acc_list.append(accuracy)\n",
    "    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n",
    "         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
    "ax1.plot(mean_train_losses, label='train')\n",
    "ax1.plot(mean_valid_losses, label='valid')\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "ax2.plot(valid_acc_list, label='valid acc')\n",
    "ax2.legend()\n",
    "# plt.savefig(path + \"/losses\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds = torch.LongTensor()\n",
    "\n",
    "for i, images in enumerate(test_loader):\n",
    "    outputs = model(images)\n",
    "    \n",
    "    pred = outputs.max(1, keepdim=True)[1]\n",
    "    test_preds = torch.cat((test_preds, pred), dim=0)\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "out_df['ID'] = np.arange(1, len(X_test.index)+1)\n",
    "out_df['label'] = test_preds.numpy()\n",
    "\n",
    "# out_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('fed-cl-req')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baf0f7b767fca9168049f46cc897bb3f071d816f9064c28d8131bee0252313b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
